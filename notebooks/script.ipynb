{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9834995,"sourceType":"datasetVersion","datasetId":6032649},{"sourceId":12051653,"sourceType":"datasetVersion","datasetId":7584637}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nimport nltk\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder # to convert classes to number\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# Add environment Packages paths to conda\nimport os, sys, warnings\nimport pandas as pd\nimport numpy as np\nwarnings.simplefilter(\"ignore\")\n\n# Text preprocessing packages\nimport nltk # Text libarary\n# import tweepy\n# nltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T22:16:47.127253Z","iopub.execute_input":"2025-06-03T22:16:47.127859Z","iopub.status.idle":"2025-06-03T22:16:47.133476Z","shell.execute_reply.started":"2025-06-03T22:16:47.127832Z","shell.execute_reply":"2025-06-03T22:16:47.132660Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Chargement de data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hdatasetvf/projectHA_DATASET.csv')\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T22:16:47.143685Z","iopub.execute_input":"2025-06-03T22:16:47.143962Z","iopub.status.idle":"2025-06-03T22:16:47.190444Z","shell.execute_reply.started":"2025-06-03T22:16:47.143941Z","shell.execute_reply":"2025-06-03T22:16:47.189583Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      annotation_id                   created_at    id  lead_time sentiment  \\\n0                 1  2024-06-09T22:17:12.606256Z  1010      3.231   Neutral   \n1                 1  2024-06-09T22:17:18.084764Z  1011      4.059  Negative   \n2                 1  2024-06-09T22:17:21.820275Z  1012      2.521  Positive   \n3                 1  2024-06-09T22:17:26.600887Z  1013      3.291  Negative   \n4                 1  2024-06-09T22:17:30.816264Z  1014      2.682  Positive   \n...             ...                          ...   ...        ...       ...   \n1846              1  2024-09-23T17:04:36.605020Z  4480      2.004  Negative   \n1847              1  2024-09-23T17:04:39.993676Z  4481      2.038  Positive   \n1848              1  2024-09-23T17:04:44.693953Z  4482      2.266  Negative   \n1849              1  2024-09-23T17:04:51.409203Z  4483      5.389   Neutral   \n1850              1  2024-09-23T17:04:56.463832Z  4484      2.539  Negative   \n\n                                                text  \\\n0                                               اهيه   \n1                                  شيباني افجل إيشير   \n2                    السلام عليكم ورحمة الله وبركاته   \n3                             انت مانك محترم يواجعة    \n4                                                زين   \n...                                              ...   \n1846                               أمر من احدج لحمير   \n1847                            شوكت الخاطر لا اتدگك   \n1848                   حنش الكايل، الا كاتل ول مكتول   \n1849  الحجر، أل طاحت اعليه ينعطب، ول طاح اعليه ينعطب   \n1850                                   إِگيدوه لخيوط   \n\n                       updated_at  \n0     2024-06-09T22:17:12.606256Z  \n1     2024-06-09T22:17:18.084764Z  \n2     2024-06-09T22:17:21.820275Z  \n3     2024-06-09T22:17:26.600887Z  \n4     2024-06-09T22:17:30.816264Z  \n...                           ...  \n1846  2024-09-23T17:04:36.605020Z  \n1847  2024-09-23T17:04:39.993676Z  \n1848  2024-09-23T17:04:44.693953Z  \n1849  2024-09-23T17:04:51.409203Z  \n1850  2024-09-23T17:04:56.463832Z  \n\n[1851 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>annotation_id</th>\n      <th>created_at</th>\n      <th>id</th>\n      <th>lead_time</th>\n      <th>sentiment</th>\n      <th>text</th>\n      <th>updated_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2024-06-09T22:17:12.606256Z</td>\n      <td>1010</td>\n      <td>3.231</td>\n      <td>Neutral</td>\n      <td>اهيه</td>\n      <td>2024-06-09T22:17:12.606256Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2024-06-09T22:17:18.084764Z</td>\n      <td>1011</td>\n      <td>4.059</td>\n      <td>Negative</td>\n      <td>شيباني افجل إيشير</td>\n      <td>2024-06-09T22:17:18.084764Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2024-06-09T22:17:21.820275Z</td>\n      <td>1012</td>\n      <td>2.521</td>\n      <td>Positive</td>\n      <td>السلام عليكم ورحمة الله وبركاته</td>\n      <td>2024-06-09T22:17:21.820275Z</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2024-06-09T22:17:26.600887Z</td>\n      <td>1013</td>\n      <td>3.291</td>\n      <td>Negative</td>\n      <td>انت مانك محترم يواجعة</td>\n      <td>2024-06-09T22:17:26.600887Z</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2024-06-09T22:17:30.816264Z</td>\n      <td>1014</td>\n      <td>2.682</td>\n      <td>Positive</td>\n      <td>زين</td>\n      <td>2024-06-09T22:17:30.816264Z</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1846</th>\n      <td>1</td>\n      <td>2024-09-23T17:04:36.605020Z</td>\n      <td>4480</td>\n      <td>2.004</td>\n      <td>Negative</td>\n      <td>أمر من احدج لحمير</td>\n      <td>2024-09-23T17:04:36.605020Z</td>\n    </tr>\n    <tr>\n      <th>1847</th>\n      <td>1</td>\n      <td>2024-09-23T17:04:39.993676Z</td>\n      <td>4481</td>\n      <td>2.038</td>\n      <td>Positive</td>\n      <td>شوكت الخاطر لا اتدگك</td>\n      <td>2024-09-23T17:04:39.993676Z</td>\n    </tr>\n    <tr>\n      <th>1848</th>\n      <td>1</td>\n      <td>2024-09-23T17:04:44.693953Z</td>\n      <td>4482</td>\n      <td>2.266</td>\n      <td>Negative</td>\n      <td>حنش الكايل، الا كاتل ول مكتول</td>\n      <td>2024-09-23T17:04:44.693953Z</td>\n    </tr>\n    <tr>\n      <th>1849</th>\n      <td>1</td>\n      <td>2024-09-23T17:04:51.409203Z</td>\n      <td>4483</td>\n      <td>5.389</td>\n      <td>Neutral</td>\n      <td>الحجر، أل طاحت اعليه ينعطب، ول طاح اعليه ينعطب</td>\n      <td>2024-09-23T17:04:51.409203Z</td>\n    </tr>\n    <tr>\n      <th>1850</th>\n      <td>1</td>\n      <td>2024-09-23T17:04:56.463832Z</td>\n      <td>4484</td>\n      <td>2.539</td>\n      <td>Negative</td>\n      <td>إِگيدوه لخيوط</td>\n      <td>2024-09-23T17:04:56.463832Z</td>\n    </tr>\n  </tbody>\n</table>\n<p>1851 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"df = pd.DataFrame(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T22:16:47.191943Z","iopub.execute_input":"2025-06-03T22:16:47.192265Z","iopub.status.idle":"2025-06-03T22:16:47.196621Z","shell.execute_reply.started":"2025-06-03T22:16:47.192237Z","shell.execute_reply":"2025-06-03T22:16:47.195730Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# split data","metadata":{}},{"cell_type":"code","source":"# df = pd.DataFrame(df)\nX = df['text'] # Input features\ny = df['sentiment']               # Target variable\ntfidf_vectorizer = TfidfVectorizer()\n\n\n# # Transformation de X en vecteurs TF-IDF\n# X_tfidf = tfidf_vectorizer.fit_transform(X)\n# Encoder les étiquettes de classe en valeurs numériques\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n\n\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(X)\n\n# 🔥 Convertir en tableau dense ici\nX_dense = X.toarray()\n\n# Séparer en train/test\nX_train, X_test, y_train, y_test = train_test_split(X_dense, y_encoded, test_size=0.2, random_state=42)\n\n\n# # Division des données en ensembles d'entraînement et de test (80% pour l'entraînement, 20% pour le test)\n# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_encoded, test_size=0.20, random_state=42)\n\n\n# smote = SMOTE()\n# X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n# Affichage des dimensions des ensembles d'entraînement et de test\nprint(\"Shape of X_train:\", X_train.shape)\nprint(\"Shape of y_train:\", y_train.shape)\nprint(\"Shape of X_test:\", X_test.shape)\nprint(\"Shape of y_test:\", y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T22:23:06.341182Z","iopub.execute_input":"2025-06-03T22:23:06.341764Z","iopub.status.idle":"2025-06-03T22:23:06.473799Z","shell.execute_reply.started":"2025-06-03T22:23:06.341738Z","shell.execute_reply":"2025-06-03T22:23:06.473033Z"}},"outputs":[{"name":"stdout","text":"Shape of X_train: (1480, 4688)\nShape of y_train: (1480,)\nShape of X_test: (371, 4688)\nShape of y_test: (371,)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"\nimport sys\nsys.path.append('/kaggle/input/classifysvm/svmclassify')\nfrom svm_classifier import SVM\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T22:23:10.796326Z","iopub.execute_input":"2025-06-03T22:23:10.796679Z","iopub.status.idle":"2025-06-03T22:23:10.801057Z","shell.execute_reply.started":"2025-06-03T22:23:10.796655Z","shell.execute_reply":"2025-06-03T22:23:10.800070Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# use case","metadata":{}},{"cell_type":"code","source":"clf = SVM(learning_rate=0.001, lambda_param=0.01, n_iters=1000)\nclf.train(X_train, y_train)\ny_pred = clf.predict(X_test)\nacc = clf.evaluate(X_test, y_test)\nprint(f\"Accuracy: {acc:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T22:23:12.877388Z","iopub.execute_input":"2025-06-03T22:23:12.877739Z","iopub.status.idle":"2025-06-03T22:24:01.148140Z","shell.execute_reply.started":"2025-06-03T22:23:12.877716Z","shell.execute_reply":"2025-06-03T22:24:01.147219Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.37\n","output_type":"stream"}],"execution_count":26}]}